{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e64290",
   "metadata": {},
   "source": [
    "# Prototype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfea0d",
   "metadata": {},
   "source": [
    "## Importing packages and setting up API/LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fb2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from dotenv import load_dotenv, set_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0bf683d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "CACHE_FILE ='processed_codes.json'\n",
    "RAW_DATA_DIR = 'weekly_raw_data'\n",
    "PROCESSED_DATA_DIR = 'all_reports_parquet_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6115666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the API\n",
    "authURL = \"https://www.warcraftlogs.com/oauth/authorize\"\n",
    "tokenURL= \"https://www.warcraftlogs.com/oauth/token\"\n",
    "api_key = os.getenv('client_secret')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77f6f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format=\"%(asctime)s - %(name)s -%(levelname)s -%(message)s\",\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22358a19",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d8e9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for handling the token needed for authorization. \n",
    "\n",
    "def read_token(token_name='WARCRAFTLOGS_TOKEN'):\n",
    "    \"\"\"\n",
    "    Reads a token from a .env file.\n",
    "\n",
    "    This function first loads environment variables from a .env file\n",
    "    if it exists. It then attempts to retrieve the specified token\n",
    "    from the environment.\n",
    "\n",
    "    Args:\n",
    "        token_name (str): The name of the environment variable that holds\n",
    "                          the token.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The token string if found, otherwise None.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    token = os.getenv(token_name)\n",
    "\n",
    "    if token is None:\n",
    "        print(f\"Error: The token '{token_name}' was not found in the .env file.\")\n",
    "        logger.info(f\"Error: The token '{token_name}' was not found in the .env file.\")\n",
    "        return None\n",
    "\n",
    "    return token\n",
    "\n",
    "def store_token(token, token_name='WARCRAFTLOGS_TOKEN'):\n",
    "    \"\"\"\n",
    "    Saves a new token to the .env file.\n",
    "\n",
    "    Args:\n",
    "        token (str): The token to be saved.\n",
    "        token_name (str): The name of the environment variable.\n",
    "    \"\"\"\n",
    "    dotenv_path = os.path.join(os.getcwd(), '.env')\n",
    "    set_key(dotenv_path, token_name, token)\n",
    "\n",
    "    print(f\"Successfully saved new token to the .env file under key '{token_name}'.\")\n",
    "    logger.info(f\"Successfully saved new token to the .env file under key '{token_name}'.\")\n",
    "\n",
    "def get_new_token(client_id, client_secret):\n",
    "    \"\"\"\n",
    "    Gets a new access token from the Warcraft Logs API using the Client Credentials flow.\n",
    "    If successful, it saves the new token to the .env file.\n",
    "\n",
    "    Args:\n",
    "        client_id (str): The public client ID for your application.\n",
    "        client_secret (str): The confidential client secret for your application.\n",
    "\n",
    "    Returns:\n",
    "        str or None: The new access token string if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    url = \"https://www.warcraftlogs.com/oauth/token\"\n",
    "    data = {'grant_type': 'client_credentials'}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, data=data, auth=(client_id, client_secret))\n",
    "\n",
    "        token_data = response.json()\n",
    "        access_token = token_data.get('access_token')\n",
    "\n",
    "        if access_token:\n",
    "            print(\"Successfully retrieved a new access token.\")\n",
    "            logger.info(\"Successfully retrieved a new access token.\")\n",
    "            store_token(access_token)\n",
    "            return access_token\n",
    "        else:\n",
    "            print(\"Error: Access token not found in the API response.\")\n",
    "            logger.info(\"Error: Access token not found in the API response.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while getting a new token: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11f76cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base function for making querys\n",
    "def make_query(token: str, query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Makes a GraphQL query to the Warcraft Logs API using the provided access token.\n",
    "\n",
    "    Args:\n",
    "        token (str): The access token to use for authorization.\n",
    "        query (str): The GraphQL query string.\n",
    "\n",
    "    Returns:\n",
    "        dict or None: The JSON response data if successful, otherwise None.\n",
    "    \"\"\"\n",
    "    url = \"https://www.warcraftlogs.com/api/v2/client\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {'query': query}\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred while making the GraphQL query: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e03337c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting fightIDs. \n",
    "# One report can contain multiple fights (one fight = one whole dungeon-run)\n",
    "\n",
    "def make_fightID_query(report_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the fights in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{\n",
    "                                                        title\n",
    "                                                        fights(translate: true, difficulty: 10) {{\n",
    "                                                            id\n",
    "                                                            friendlyPlayers\n",
    "                                                            gameZone{{\n",
    "                                                                name\n",
    "                                                                }}\n",
    "                                                            difficulty\n",
    "                                                            keystoneLevel\n",
    "                                                        }}\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_fightID(token: str, report_code: str) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Makes the API-call with the query to get data about the fights in the report.\n",
    "\n",
    "    Args:\n",
    "        token (str): The access token to use for authorization.\n",
    "        report_code (str): The reportcode for a report on warcraftlogs.\n",
    "\n",
    "    Returns:\n",
    "        df (pd.DataFrame): A dataframe with the ID of the diffrent fights in the report.\n",
    "    \"\"\"\n",
    "    test_query = make_query(token, make_fightID_query(report_code))\n",
    "    df = pd.json_normalize(test_query, record_path=['data', 'reportData', 'report', 'fights'])\n",
    "    return df\n",
    "\n",
    "def clean_fightID_df(dataframe):\n",
    "    \"\"\" \n",
    "    Cleans the fightID_df dataframe.\n",
    "\n",
    "    This is what limits the data to dungeons (where you are 5 players) and not raids. \n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The fightsID_df\n",
    "    \n",
    "    Returns: \n",
    "        df_filtered (pd.DataFrame): A cleaned version of the fightsID dataframe.\n",
    "    \"\"\"\n",
    "    df = dataframe\n",
    "    # Only take the fights where you have 5 players\n",
    "    mask = df['friendlyPlayers'].apply(len) == 5\n",
    "    df_filtered = df[mask]\n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50d258f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for adding gameID data (name, report ID, game ID) for the report.\n",
    "\n",
    "def make_gameID_query(report_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the character ID's in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    masterData{{\n",
    "                                                        actors(type: \"Player\"){{\n",
    "                                                            name\n",
    "                                                            gameID\n",
    "                                                            id\n",
    "                                                            }}\n",
    "                                                        }}\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_gameID(token: str, report_code: str) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Makes the API-call with the query to get data about the character ID's.\n",
    "\n",
    "    Args:\n",
    "        token (str): The access token to use for authorization.\n",
    "        report_code (str): The reportcode for a report on warcraftlogs.\n",
    "\n",
    "    Returns:\n",
    "        df_gameID (pd.DataFrame): A dataframe with the characters name, gameID and report id.\n",
    "    \"\"\"\n",
    "    gameID_query = make_query(token, make_gameID_query(report_code))\n",
    "    df_gameID = pd.json_normalize(gameID_query, record_path=['data', 'reportData', 'report', 'masterData', 'actors'])\n",
    "    return df_gameID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e3e836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for damage and healing in a fight.\n",
    "\n",
    "def make_damage_query(report_code: str, fight_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the damage in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    table(fightIDs: [{fight_id}], dataType: DamageDone, hostilityType: Friendlies)\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def make_healing_query(report_code: str, fight_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the healing in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    table(fightIDs: [{fight_id}], dataType: Healing, hostilityType: Friendlies)\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_damage_and_healing(token: str, report_code: str, fight_ID: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Uses a token,reportcode and the fight ID for warcraftlogs to get data for damage and healing.\n",
    "\n",
    "    Args:\n",
    "        token (str): The access token to use for authorization.\n",
    "        report_code (str): The reportcode for a report on warcraftlogs.\n",
    "        fight_ID (int): A number indicating what fight in the report that was used.\n",
    "    Returns:\n",
    "        DataFrame with data for damage and healing.\n",
    "    \"\"\"\n",
    "    #Damage part\n",
    "    damage_query = make_query(token, make_damage_query(report_code, fight_ID))\n",
    "    df_dmg_temp = pd.json_normalize(damage_query, record_path=['data', 'reportData', 'report', 'table', 'data', 'entries'])\n",
    "    dmg_columns = ['name', 'type', 'itemLevel', 'total']\n",
    "    df_damage = df_dmg_temp[dmg_columns]\n",
    "    df_damage.columns = ['name', 'class', 'ilvl', 'Dps']\n",
    "            \n",
    "    #healing part\n",
    "    healing_query = make_query(token, make_healing_query(report_code, fight_ID))\n",
    "    df_heal_temp = pd.json_normalize(healing_query, record_path=['data', 'reportData', 'report', 'table', 'data', 'entries'])\n",
    "    heal_columns = ['name', 'total']\n",
    "    df_heal = df_heal_temp[heal_columns]\n",
    "    df_heal.columns = ['name', 'Healing']\n",
    "            \n",
    "    #Merge them\n",
    "    merged_df = pd.merge(df_heal, df_damage, on='name')\n",
    "    #Reorder columns\n",
    "    healing_column = merged_df.pop('Healing')\n",
    "    merged_df.insert(4, 'Healing', healing_column)\n",
    "\n",
    "    return(merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90ee4277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting the starting time of the report.\n",
    "\n",
    "\n",
    "def make_report_start_query(report_code: str) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the start time in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    startTime\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_report_start(token: str, report_code: str) -> int:\n",
    "    \"\"\" \n",
    "    Get the starting time of the report.\n",
    "\n",
    "    Args:\n",
    "        token(str): The token for making the API call\n",
    "        report_code(str): The report code for the report we're looking at.\n",
    "\n",
    "    Returns:\n",
    "        start_time(int): The startingtime as an int (in UNIX-format)\n",
    "    \"\"\"\n",
    "    date_query = make_query(token, make_report_start_query(report_code))\n",
    "    start_time = int(round((date_query['data']['reportData']['report']['startTime'] / 1000)))\n",
    "    return start_time\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12d5bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for getting the starting time for a fight. \n",
    "# Also uses UNIX, but with 0 as the reports starting time.\n",
    "\n",
    "def make_fight_start_query(report_code: str, id: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the starttime for a fight in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "        id (int): Tells the program what fight in the report we're looking at. \n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    fights(fightIDs: {id}){{\n",
    "                                                        id\n",
    "                                                        startTime\n",
    "                                                        }}\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_fight_start(token: str, report_code: str, id: int, unix_report_start: int) -> float:\n",
    "    \"\"\" \n",
    "    Makes the API call to get the starting time for a fight. \n",
    "    The starting time will be in UNIX format, in relation to the starttime of the report.\n",
    "    Removes the millisecond part from UNIX.\n",
    "\n",
    "    Args: \n",
    "        token (str): token for making the API call\n",
    "        report_code (str): the code for the report we're looking at.\n",
    "        id (int): Tells the program what fight in the report we're looking at.\n",
    "        unix_report_start (int): The startingtime for the report.\n",
    "    \"\"\"\n",
    "    date_query = make_query(token, make_fight_start_query(report_code, id))\n",
    "    unix_fight = (date_query['data']['reportData']['report']['fights'][0]['startTime'])/1000\n",
    "    \n",
    "    # Adds the starttime of the fight to the starttime of the report so we get a correct conversion later.\n",
    "    unix_fight_start = unix_report_start + unix_fight\n",
    "    return unix_fight_start\n",
    "\n",
    "# Converts UNIX to datetime\n",
    "def convert_time(time_unix: float) -> datetime:\n",
    "    \"\"\" \n",
    "    Converts the time from UNIX to a datetime object.\n",
    "\n",
    "    Args: \n",
    "        time_unix (float): A number representing the time\n",
    "\n",
    "    Returns:\n",
    "        time (datetime): The date and time as a datetime object. \n",
    "    \"\"\"\n",
    "    time = datetime.fromtimestamp(time_unix)\n",
    "    return time\n",
    "\n",
    "# Get's the name of the dungeon\n",
    "def get_dungeon_name(fightID: int, df: pd.DataFrame) -> str:\n",
    "    \"\"\" \n",
    "    Get the name of the dungeon for the corresponding fight.\n",
    "\n",
    "    Args:\n",
    "        fightID (int): Identifies what fight we want the name for.\n",
    "        df (dataFrame): dataFrame with the data we need.\n",
    "\n",
    "    Returns:\n",
    "        dungeon_name (str): The name of the dungeon.\n",
    "\n",
    "    \"\"\"\n",
    "    mask = df['id'] == fightID\n",
    "    dungeon_name = df.loc[mask, 'gameZone.name'].squeeze()\n",
    "    if pd.isna(dungeon_name):\n",
    "        return (\"No name found\")\n",
    "    else:\n",
    "        return dungeon_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a46a4342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for deaths in a fight. \n",
    "\n",
    "def make_deaths_query(report_code: str, fight_id: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a query-string for getting information about the deaths in the report.\n",
    "\n",
    "    Args:\n",
    "        report_code (str): Uniqe code for the report used in the query.\n",
    "\n",
    "    Returns:\n",
    "        query (str): Query string to be used in a api call.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    table(fightIDs: [{fight_id}], dataType: Deaths, hostilityType: Friendlies)\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "\n",
    "def get_deaths(token: str, report_code: str, fight_id: int) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Makes the API call for getting information about the deaths during the fight. \n",
    "    If there are no deaths returns a empty dataframe.\n",
    "\n",
    "    Args:\n",
    "        token (str): token for making the API call\n",
    "        report_code (str): the code for the report we're looking at.\n",
    "        id (int): Tells the program what fight in the report we're looking at.\n",
    "\n",
    "    Returns: \n",
    "        df_deaths (pd.DataFrame): A dataframe with information about the deaths during the fight.\n",
    "    \"\"\"\n",
    "    deaths_query = make_query(token, make_deaths_query(report_code, fight_id))\n",
    "    df_deaths_temp = pd.json_normalize(deaths_query, record_path=['data', 'reportData', 'report', 'table', 'data', 'entries'])\n",
    "    if 'name' in df_deaths_temp.columns:\n",
    "        deaths_columns = ['name']\n",
    "        df_deaths = df_deaths_temp[deaths_columns]\n",
    "        return df_deaths\n",
    "    else:\n",
    "        return pd.DataFrame(columns=['name'])\n",
    "\n",
    "\n",
    "def make_name_id_death_df(deaths_dataframe: pd.DataFrame, name_id_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" \n",
    "    Creates a new dataframe where the deaths for each character is summarized and the ID of each character is shown.\n",
    "\n",
    "    Args:\n",
    "        deaths_dataframe(pd.DataFrame): dataframe with the deaths\n",
    "        name_id_dataframe(pd.DataFrame): dataframe with information about the characters name and ID.\n",
    "    \n",
    "    Returns:\n",
    "        df_name_id_deaths(pd.DataFrame): dataframe with the name of the character, it's report ID and number deaths.\n",
    "    \"\"\"\n",
    "    # Counts the deaths in the dataframe\n",
    "    death_counts = deaths_dataframe.value_counts()\n",
    "\n",
    "    # Merges the dataframes\n",
    "    df_name_id_deaths = name_id_dataframe.merge(death_counts, how='outer', on='name')\n",
    "\n",
    "    # Changes NaN to 0\n",
    "    df_name_id_deaths = df_name_id_deaths.fillna(0)\n",
    "\n",
    "    # Renames the columns\n",
    "    df_name_id_deaths = df_name_id_deaths.rename(columns={'count':'deaths'})\n",
    "\n",
    "    # Makes sure the death's columns are ints. \n",
    "    df_name_id_deaths['deaths'] = df_name_id_deaths['deaths'].astype(int)\n",
    "    \n",
    "    return df_name_id_deaths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fc7343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for managing report codes\n",
    "\n",
    "def make_report_codes_query(user_id: int) -> str:\n",
    "    \"\"\" \n",
    "    Makes the API call to get new codes for the week. \n",
    "\n",
    "    Args:\n",
    "        user_id (int): Int for representing the user whom uploaded the reports.\n",
    "\n",
    "    Returns:\n",
    "        query (str): String with the query\n",
    "    \n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                reports(userID: {user_id}, limit: 100){{                        \n",
    "                                                    data{{\n",
    "                                                        code\n",
    "                                                        title\n",
    "                                                        startTime\n",
    "                                                        }}\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_report_codes(token: str) -> list:\n",
    "    \"\"\" \n",
    "    Fetches new codes for the week.\n",
    "\n",
    "    Args: \n",
    "        token (str): token for making the api call.\n",
    "    \n",
    "    Returns:\n",
    "        codes (list): a list with report codes.\n",
    "    \n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    user_ids = ['297125', '291792']\n",
    "    date = datetime.now()\n",
    "    date_UNIX = date.timestamp()\n",
    "    date_UNIX_past = date_UNIX - (60*60*24*7)\n",
    "    for id in user_ids:\n",
    "        report_codes = make_query(token, make_report_codes_query(id))\n",
    "        df = pd.json_normalize(report_codes, record_path=['data', 'reportData', 'reports', 'data'])\n",
    "        df['startTime'] = df['startTime'] / 1000\n",
    "        \n",
    "        mask = df['startTime'] > date_UNIX_past\n",
    "        filtered_df = df[mask]\n",
    "        new_codes = filtered_df['code'].tolist()\n",
    "        codes.append(new_codes)\n",
    "    return codes\n",
    "\n",
    "\n",
    "def check_codes(new_codes: list, old_codes: set) -> list:\n",
    "    \"\"\"\n",
    "    Compares preivous codes with the new list to check for duplicates.\n",
    "\n",
    "    Args:\n",
    "        new_codes (list): List with all the new codes as strings.\n",
    "        old_codes (list): List with all the old codes as strings.\n",
    "    Returns:\n",
    "        new_codes (list): The list with new codes but with duplicates removed.\n",
    "    \"\"\"\n",
    "    set1 = set(new_codes)\n",
    "    set2 = set(old_codes)\n",
    "    \n",
    "    common_codes = set1.intersection(set2)\n",
    "    for code in common_codes:\n",
    "        if code in new_codes:\n",
    "            new_codes.remove(code)\n",
    "\n",
    "    return new_codes\n",
    "\n",
    "def load_cache_codes() -> list:\n",
    "    \"\"\"\n",
    "    Loads used codes from a cache file.\n",
    "\n",
    "    Returns:\n",
    "        set (set): a set with the old codes.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        try:\n",
    "            with open(CACHE_FILE, 'r') as f:\n",
    "                return list(json.load(f))\n",
    "        except (IOError, json.JSONDecodeError) as e:\n",
    "            print(f\"Error loading cache file: {e}\")\n",
    "            # Start with an empty cache if there's an error\n",
    "            return list()\n",
    "    return list()\n",
    "\n",
    "def save_cache_codes(codes: set):\n",
    "    \"\"\"\n",
    "    Saves used codes to a cache file.\n",
    "\n",
    "    Args:\n",
    "        codes (list): a list with all codes.\n",
    "    \"\"\"\n",
    "    codes_as_list = list(codes)\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'w') as f:\n",
    "            json.dump(codes_as_list, f, indent=4)\n",
    "    except IOError as e:\n",
    "        print(f\"Error saving cache file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bfa72c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for managing the data\n",
    "\n",
    "# Saves the weekly reports as JSON in the raw data folder\n",
    "\n",
    "def save_weekly_data(code: str, input_data: pd.DataFrame):\n",
    "    \"\"\" \n",
    "    Saves data from a report to a JSON file used for temporary storage.\n",
    "\n",
    "    Args:\n",
    "        code (str): code for a single report as a string\n",
    "        input_data (dataFrame): dataframe with the data for the report\n",
    "\n",
    "    \"\"\"\n",
    "    # Create folder for temporary storage\n",
    "    if not os.path.exists(RAW_DATA_DIR):\n",
    "        os.makedirs(RAW_DATA_DIR)\n",
    "\n",
    "    file_path = os.path.join(RAW_DATA_DIR, f\"{code}.json\")\n",
    "\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"JSON file for '{code}' already exists. Skipping API call.\")    \n",
    "\n",
    "    # Converts the data to a list for JSON storage. Since the dataframe contains datetime data\n",
    "    # we use json_string to conserve it. \n",
    "    json_string = input_data.to_json(orient='records', date_format='iso')\n",
    "    data_list = json.loads(json_string)\n",
    "\n",
    "    data = {\"report_code\": code, \"Data\": data_list}\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "\n",
    "def append_weekly_data_to_dataset():\n",
    "    \"\"\" \n",
    "    Takes the JSON-files in the temporary folder and appends to a parquet dataset.\n",
    "    \"\"\"\n",
    "    #Empty list to which we append data\n",
    "    all_data = []\n",
    "\n",
    "    # Check so there is data\n",
    "    if not os.path.exists(RAW_DATA_DIR):\n",
    "        print(\"Weekly raw data directory does not exist. No new data to append.\")\n",
    "        return\n",
    "    \n",
    "    for filename in os.listdir(RAW_DATA_DIR):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(RAW_DATA_DIR, filename)\n",
    "            with open(file_path, 'r') as f:\n",
    "                all_data.append(json.load(f))\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"No new data to append\")\n",
    "        return\n",
    "    \n",
    "    # Cleaning the data so it's easer to handle when opening it in the future.\n",
    "    df_new = pd.DataFrame(all_data)\n",
    "    df_exploded = df_new.explode('Data')\n",
    "    df_final = pd.json_normalize(df_exploded['Data'])\n",
    "\n",
    "    # Add a column to the data for indicating when it was added to the dataset. \n",
    "    current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    df_final['runDate'] = current_date\n",
    "    print(f\"Loaded {len(df_new)} new reports into a DataFrame.\")\n",
    "\n",
    "    # Convert the pandas DataFrame to a PyArrow Table\n",
    "    table_new = pa.Table.from_pandas(df_final)\n",
    "\n",
    "    # Append the new data to the Parquet dataset\n",
    "    print(f\"Appending new data to the '{PROCESSED_DATA_DIR}' dataset...\")\n",
    "    pq.write_to_dataset(table_new, PROCESSED_DATA_DIR,\n",
    "                        partition_cols=['runDate'],\n",
    "                        basename_template='part-{i}.parquet')\n",
    "    \n",
    "    print(\"New data successfully appended to the Parquet dataset.\")\n",
    "\n",
    "    # Clean up the weekly JSON files\n",
    "    for filename in os.listdir(RAW_DATA_DIR):\n",
    "        os.remove(os.path.join(RAW_DATA_DIR, filename))\n",
    "    os.rmdir(RAW_DATA_DIR)\n",
    "    print(\"Cleaned up weekly raw data directory.\")\n",
    "\n",
    "\n",
    "def look_at_dataset():\n",
    "    \"\"\" \n",
    "    Use to load the dataset (used when making the script in jupyter notebook)\n",
    "\n",
    "    Returns:\n",
    "        df (dataframe): dataframe with all the data. \n",
    "    \"\"\"\n",
    "    file_path = 'all_reports_parquet_dataset/'\n",
    "\n",
    "    df = pd.read_parquet(file_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38949d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90d9d24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main script\n",
    "def main():\n",
    "    CACHE_FILE ='processed_codes.json'\n",
    "    RAW_DATA_DIR = 'weekly_raw_data'\n",
    "    PROCESSED_DATA_DIR = 'all_reports_parquet_dataset'\n",
    "\n",
    "    logger.info(\"Starting the script\")\n",
    "\n",
    "    # Reads the token for making API calls\n",
    "    token = read_token()\n",
    "    if not token:\n",
    "        print(\"No token found, fetching new one...\")\n",
    "        client_id = os.getenv('CLIENT_ID')\n",
    "        client_secret = os.getenv('CLIENT_SECRET')\n",
    "        response = get_new_token(client_id, client_secret)\n",
    "        token = response.json().get(\"WARCRAFTLOGS_TOKEN\")\n",
    "        \n",
    "    logger.info(\"Autherization complete\")\n",
    "\n",
    "    # Load cached reportcodes\n",
    "    old_codes = load_cache_codes()\n",
    "\n",
    "    if token:\n",
    "        try:\n",
    "            # Load new codes (function not done yet, manually add)\n",
    "            list_of_codes = get_report_codes(token)\n",
    "            print(list_of_codes)\n",
    "            # Remove codes that were present in the cache\n",
    "            weekly_codes = check_codes(list_of_codes, old_codes)\n",
    "\n",
    "            # Counter for printing the progress of the report codes. \n",
    "            counter_1 = 1\n",
    "\n",
    "            # Start going through the report-codes from the list. \n",
    "            for code in weekly_codes:\n",
    "\n",
    "                #Used for printing the progress.\n",
    "                number_of_codes = len(weekly_codes)\n",
    "                \n",
    "                # Creates a JSON file in the short storages folder, will be removed if program runs successfully.\n",
    "                file_path = os.path.join(RAW_DATA_DIR, f\"{code}.json\")\n",
    "                if os.path.exists(file_path):\n",
    "                        print(f\"JSON file for '{code}' already exists. Skipping API call.\")\n",
    "                        continue\n",
    "\n",
    "                # Get the name, id and gameID for characters in the report.\n",
    "                gameID = get_gameID(token, code)\n",
    "\n",
    "                #Get the starting time of the report.\n",
    "                unix_report_start = get_report_start(token, code)\n",
    "\n",
    "                #Get fightID for diffrent runs and then create a dict with fightID as key and playerID's for that fightID as values.\n",
    "                df_fightID = get_fightID(token, code)\n",
    "                df_fightID = clean_fightID_df(df_fightID)\n",
    "                fightID_dict = dict(zip(df_fightID['id'], df_fightID['friendlyPlayers']))\n",
    "                \n",
    "                \n",
    "                # Create empty list of dataframes and a empty dataframe used in the fight's loop.\n",
    "                list_of_dataframes = []\n",
    "                df_weekly = pd.DataFrame()\n",
    "\n",
    "                # Used for printing the progress with the fights\n",
    "                counter_2 = 1\n",
    "\n",
    "                # Start going through each fight in the report (reminder: a fight equals a whole dungeon-run)\n",
    "                for key in fightID_dict:\n",
    "                    \n",
    "                    # Used for printing the progress of the fights.\n",
    "                    number_of_fights = len(fightID_dict)\n",
    "\n",
    "                    # Get the start time of the fight\n",
    "                    start_time_fight = convert_time(get_fight_start(token, code, key, unix_report_start))\n",
    "\n",
    "                    # Get the player names and ids for the specific run.\n",
    "                    df_name_id = gameID[gameID['id'].isin(fightID_dict[key])]\n",
    "\n",
    "                    # Get healing and damage for the players in the run.\n",
    "                    df_dmg_healing = get_damage_and_healing(token, code, key)\n",
    "\n",
    "                    # Get a list of all deaths for the run. Sum them up and merge with the name_id dataframe.\n",
    "                    # Players with no deaths will be missing in death_counts, so fillna(0) is used to set the number to 0 instead of NaN.\n",
    "                    df_deaths = get_deaths(token, code, key)\n",
    "                    df_name_id_deaths = make_name_id_death_df(df_deaths, df_name_id)\n",
    "\n",
    "                    #Merge the two dataframes on name.\n",
    "                    df_complete = pd.merge(df_name_id_deaths, df_dmg_healing, how='outer', on='name')\n",
    "\n",
    "                    # Add the dungon name and starttime to the dataframe\n",
    "                    dungeon_name = get_dungeon_name(key, df_fightID)\n",
    "                    df_complete['DungeonName'] = dungeon_name\n",
    "                    df_complete['StartTime'] = start_time_fight\n",
    "\n",
    "                    # Add the dataframe to a list for future merge\n",
    "                    list_of_dataframes.append(df_complete)\n",
    "                    \n",
    "                    logger.info(f\"Done with fight {counter_2} of {number_of_fights}\")\n",
    "                    counter_2 = counter_2 + 1\n",
    "\n",
    "                # Merge the dataframes from the report to one single dataframe\n",
    "                df_weekly = pd.concat(list_of_dataframes, ignore_index = True)  \n",
    "                df_weekly['reportCode'] = code\n",
    "                old_codes.append(code)\n",
    "                save_weekly_data(code, df_weekly)\n",
    "                \n",
    "                logger.info(f\"Done with code {counter_1} of {number_of_codes}\")\n",
    "                counter_1 = counter_1 + 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            # If an error occurs, this block will execute\n",
    "            error_message = f\"Error processing code '{code}': {e}\\n\"\n",
    "            error_details = traceback.format_exc()\n",
    "            \n",
    "            # Get the current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            # Save the error to a separate file.\n",
    "            # 'a' stands for 'append' so you don't overwrite previous errors.\n",
    "            with open(\"error_log.txt\", \"a\") as error_file:\n",
    "                error_file.write(f\"--- Timestamp: {timestamp} ---\\n\")\n",
    "                error_file.write(error_message)\n",
    "                error_file.write(error_details)\n",
    "                error_file.write(\"-\" * 50 + \"\\n\\n\")\n",
    "\n",
    "            print(f\"An error occurred for code '{code}'. The details have been saved to error_log.txt. Continuing to the next code...\")\n",
    "        \n",
    "        # Saves the codes to the cache file    \n",
    "        save_cache_codes(old_codes)\n",
    "\n",
    "        # Appends the data to the parquet dataset.\n",
    "        append_weekly_data_to_dataset()\n",
    "\n",
    "        print(\"Program ran successfully\")\n",
    "\n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da7db994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6fQdTBJqnLmp72yK', 'xahRN9gHBZyK2FfC', 'HmXGDagT6pfN9Y8w', 'zjLya1v8Z6K9mdwC', 'qba1cXCnYhy9HFPr', 'gcBfzwxkQKW8A9Mq', 'RQzYL7FcCkjGyA3N', 'QwmHZMhvb3P2NWyX']\n"
     ]
    }
   ],
   "source": [
    "# Getting report codes.\n",
    "token = read_token()\n",
    "# KARL 297125\n",
    "# MARCUS 291792\n",
    "def make_report_codes_query(user_id: int) -> str:\n",
    "    \"\"\" \n",
    "    Makes the API call to get new codes for the week. \n",
    "\n",
    "    Args:\n",
    "        user_id (int): Int for representing the user whom uploaded the reports.\n",
    "\n",
    "    Returns:\n",
    "        query (str): String with the query\n",
    "    \n",
    "    \"\"\"\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                reports(userID: {user_id}, limit: 100){{                        \n",
    "                                                    data{{\n",
    "                                                        code\n",
    "                                                        title\n",
    "                                                        startTime\n",
    "                                                        }}\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "def get_report_codes(token: str) -> list:\n",
    "    \"\"\" \n",
    "    Fetches new codes for the week.\n",
    "\n",
    "    Args: \n",
    "        token (str): token for making the api call.\n",
    "    \n",
    "    Returns:\n",
    "        codes (list): a list with report codes.\n",
    "    \n",
    "    \"\"\"\n",
    "    codes = []\n",
    "    user_ids = ['297125', '291792']\n",
    "\n",
    "    date = datetime.now()\n",
    "    date_UNIX = date.timestamp()\n",
    "    date_UNIX_past = date_UNIX - (60*60*24*7)\n",
    "\n",
    "    for id in user_ids:\n",
    "\n",
    "        report_codes = make_query(token, make_report_codes_query(id))\n",
    "        df = pd.json_normalize(report_codes, record_path=['data', 'reportData', 'reports', 'data'])\n",
    "        df['startTime'] = df['startTime'] / 1000\n",
    "        mask = df['startTime'] > date_UNIX_past\n",
    "        filtered_df = df[mask]\n",
    "        new_codes = filtered_df['code'].tolist()\n",
    "        codes.extend(new_codes)\n",
    "        \n",
    "    return codes\n",
    "\n",
    "test_list = get_report_codes(token)\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cff5ac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 11:19:44,685 - __main__ -INFO -Starting the script\n",
      "2025-09-19 11:19:44,687 - __main__ -INFO -Autherization complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6fQdTBJqnLmp72yK', 'xahRN9gHBZyK2FfC', 'HmXGDagT6pfN9Y8w', 'zjLya1v8Z6K9mdwC', 'qba1cXCnYhy9HFPr', 'gcBfzwxkQKW8A9Mq', 'RQzYL7FcCkjGyA3N', 'QwmHZMhvb3P2NWyX']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-19 11:19:54,431 - __main__ -INFO -Done with fight 1 of 4\n",
      "2025-09-19 11:19:58,749 - __main__ -INFO -Done with fight 2 of 4\n",
      "2025-09-19 11:20:03,329 - __main__ -INFO -Done with fight 3 of 4\n",
      "2025-09-19 11:20:07,851 - __main__ -INFO -Done with fight 4 of 4\n",
      "2025-09-19 11:20:07,854 - __main__ -INFO -Done with code 1 of 7\n",
      "2025-09-19 11:20:16,442 - __main__ -INFO -Done with fight 1 of 8\n",
      "2025-09-19 11:20:21,539 - __main__ -INFO -Done with fight 2 of 8\n",
      "2025-09-19 11:20:26,983 - __main__ -INFO -Done with fight 3 of 8\n",
      "2025-09-19 11:20:32,133 - __main__ -INFO -Done with fight 4 of 8\n",
      "2025-09-19 11:20:37,337 - __main__ -INFO -Done with fight 5 of 8\n",
      "2025-09-19 11:20:42,394 - __main__ -INFO -Done with fight 6 of 8\n",
      "2025-09-19 11:20:47,209 - __main__ -INFO -Done with fight 7 of 8\n",
      "2025-09-19 11:20:51,874 - __main__ -INFO -Done with fight 8 of 8\n",
      "2025-09-19 11:20:51,878 - __main__ -INFO -Done with code 2 of 7\n",
      "2025-09-19 11:21:00,717 - __main__ -INFO -Done with fight 1 of 2\n",
      "2025-09-19 11:21:05,768 - __main__ -INFO -Done with fight 2 of 2\n",
      "2025-09-19 11:21:05,775 - __main__ -INFO -Done with code 3 of 7\n",
      "2025-09-19 11:21:16,449 - __main__ -INFO -Done with fight 1 of 3\n",
      "2025-09-19 11:21:24,219 - __main__ -INFO -Done with fight 2 of 3\n",
      "2025-09-19 11:21:31,443 - __main__ -INFO -Done with fight 3 of 3\n",
      "2025-09-19 11:21:31,448 - __main__ -INFO -Done with code 4 of 7\n",
      "2025-09-19 11:21:41,841 - __main__ -INFO -Done with fight 1 of 2\n",
      "2025-09-19 11:21:47,751 - __main__ -INFO -Done with fight 2 of 2\n",
      "2025-09-19 11:21:47,755 - __main__ -INFO -Done with code 5 of 7\n",
      "2025-09-19 11:21:55,421 - __main__ -INFO -Done with fight 1 of 5\n",
      "2025-09-19 11:22:00,016 - __main__ -INFO -Done with fight 2 of 5\n",
      "2025-09-19 11:22:04,441 - __main__ -INFO -Done with fight 3 of 5\n",
      "2025-09-19 11:22:09,008 - __main__ -INFO -Done with fight 4 of 5\n",
      "2025-09-19 11:22:13,523 - __main__ -INFO -Done with fight 5 of 5\n",
      "2025-09-19 11:22:13,527 - __main__ -INFO -Done with code 6 of 7\n",
      "2025-09-19 11:22:22,197 - __main__ -INFO -Done with fight 1 of 2\n",
      "2025-09-19 11:22:27,450 - __main__ -INFO -Done with fight 2 of 2\n",
      "2025-09-19 11:22:27,454 - __main__ -INFO -Done with code 7 of 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7 new reports into a DataFrame.\n",
      "Appending new data to the 'all_reports_parquet_dataset' dataset...\n",
      "New data successfully appended to the Parquet dataset.\n",
      "Cleaned up weekly raw data directory.\n",
      "Program ran successfully\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d90417",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = look_at_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3026860",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_codes = df['reportCode']\n",
    "unique_codes = list_of_codes.unique()\n",
    "unique_list = unique_codes.tolist()\n",
    "print(unique_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c81d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cache_codes(unique_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5654f5",
   "metadata": {},
   "source": [
    "## Funktioner för framtida interupts\n",
    "\n",
    "def make_interrupts_query(report_code):\n",
    "    query = f\"\"\"query PlayerDungeonMetrics{{\n",
    "                                            reportData{{\n",
    "                                                report(code: \"{report_code}\"){{                        \n",
    "                                                    table(fightIDs: [0], dataType: Interrupts, hostilityType: Friendlies)\n",
    "                                                    }}\n",
    "                                                }}\n",
    "                                            }}\"\"\" \n",
    "    return query\n",
    "\n",
    "\n",
    "def get_interrupts(token, report_code):\n",
    "    interrupts_query = make_query(token, make_interrupts_query(report_code))\n",
    "    logger.info(\"interrupts_query successful.\")\n",
    "    df_interrupts_temp = pd.json_normalize(interrupts_query, record_path=['data', 'reportData', 'report', 'table', 'data', 'entries'])\n",
    "    print(type(df_interrupts_temp))\n",
    "    print(df_interrupts_temp)\n",
    "    interrupts_columns = ['name']\n",
    "    df_interrupts = df_interrupts_temp[interrupts_columns]\n",
    "    \n",
    "    return df_interrupts\n",
    "\n",
    "def count_interrupts(df, name_column):\n",
    "    count_interrupts_df = df['name'].value_counts().reset_index()\n",
    "    count_interrupts_df.columns = ['name', 'interrupts']\n",
    "    merged_df = pd.merge(count_interrupts_df, name_column, how='outer')\n",
    "    merged_df = merged_df.fillna(0.0)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f0e118",
   "metadata": {},
   "source": [
    "        #interupts = count_interrupts(get_interrupts(token, code), gameID['name'])\n",
    "        #print(interupts)\n",
    "        interrupts_query = make_query(token, make_interrupts_query(\"ZR8G9fbxL1Q6jqXD\"))\n",
    "        logger.info(\"interrupts_query successful.\")\n",
    "        df_interrupts_temp = pd.json_normalize(interrupts_query, record_path=['data', 'reportData', 'report', 'table', 'data', 'entries'])\n",
    "        print(type(df_interrupts_temp))\n",
    "        print(df_interrupts_temp) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f27e502",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
